"""æž„å»ºè¯æ±‡è¡¨è„šæœ¬"""
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.vocabulary import Vocabulary
from src.config import Config
from collections import Counter
from tqdm import tqdm

def build_vocabularies():
    """æž„å»ºè¯æ±‡è¡¨"""
    print("ðŸ”¤ æž„å»ºè¯æ±‡è¡¨")
    print("=" * 60)
    
    # åˆ›å»ºè¯æ±‡è¡¨
    en_vocab = Vocabulary("en")
    zh_vocab = Vocabulary("zh")
    
    # åŸºç¡€è¯æ±‡
    base_en = [
        'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been',
        'in', 'on', 'at', 'by', 'with', 'to', 'from', 'for', 'of',
        'and', 'or', 'but', 'so', 'because', 'if', 'then',
        'man', 'men', 'woman', 'women', 'boy', 'girl', 'child', 'children',
        'dog', 'cat', 'animal', 'car', 'truck', 'bus', 'train', 'plane',
        'room', 'house', 'building', 'street', 'road', 'park', 'beach',
        'wearing', 'sitting', 'standing', 'walking', 'running', 'playing',
        'red', 'blue', 'green', 'yellow', 'white', 'black', 'brown',
        'small', 'big', 'large', 'little', 'old', 'young', 'new'
    ]
    
    base_zh = [
        'ä¸€ä¸ª', 'ä¸€ç¾¤', 'æ­£åœ¨', 'ç©¿ç€', 'æˆ´ç€', 'æ‹¿ç€', 'ååœ¨', 'ç«™åœ¨',
        'èµ°åœ¨', 'è·‘åœ¨', 'çŽ©åœ¨', 'çœ‹ç€', 'å¬ç€', 'è¯´ç€', 'ç¬‘ç€', 'å“­ç€',
        'ç”·äºº', 'å¥³äºº', 'ç”·å­©', 'å¥³å­©', 'å­©å­', 'å°ç‹—', 'å°çŒ«', 'åŠ¨ç‰©',
        'æ±½è½¦', 'å¡è½¦', 'å…¬äº¤è½¦', 'ç«è½¦', 'é£žæœº', 'è‡ªè¡Œè½¦', 'æ‘©æ‰˜è½¦',
        'æˆ¿é—´', 'æˆ¿å­', 'å»ºç­‘', 'è¡—é“', 'é©¬è·¯', 'å…¬å›­', 'æ²™æ»©', 'æµ·è¾¹',
        'çº¢è‰²', 'è“è‰²', 'ç»¿è‰²', 'é»„è‰²', 'ç™½è‰²', 'é»‘è‰²', 'æ£•è‰²', 'ç°è‰²',
        'å°çš„', 'å¤§çš„', 'è€çš„', 'å¹´è½»çš„', 'æ–°çš„', 'æ—§çš„', 'é•¿çš„', 'çŸ­çš„',
        'ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ'
    ]
    
    # æ·»åŠ åŸºç¡€è¯
    for word in base_en:
        en_vocab.add_word(word)
    
    for word in base_zh:
        zh_vocab.add_word(word)
    
    # ç»Ÿè®¡è¯é¢‘
    print("ðŸ“Š ç»Ÿè®¡è¯é¢‘...")
    
    # èŽ·å–è¡Œæ•°
    with open(Config.TRAIN_EN_FILE, 'r', encoding='utf-8') as f:
        total_lines = sum(1 for _ in f)
    
    # å¤„ç†è®­ç»ƒæ•°æ®
    with open(Config.TRAIN_EN_FILE, 'r', encoding='utf-8') as f_en, \
         open(Config.TRAIN_ZH_FILE, 'r', encoding='utf-8') as f_zh:
        
        for en_line, zh_line in tqdm(zip(f_en, f_zh), total=total_lines, desc="å¤„ç†"):
            en_text = en_line.strip()
            zh_text = zh_line.strip()
            
            if not en_text or not zh_text:
                continue
            
            # è‹±æ–‡åˆ†è¯å’Œç»Ÿè®¡
            en_tokens = en_vocab.tokenize_en(en_text)
            for token in en_tokens:
                en_vocab.word_freq[token] += 1
            
            # ä¸­æ–‡åˆ†è¯å’Œç»Ÿè®¡
            zh_tokens = zh_vocab.tokenize_zh(zh_text)
            for token in zh_tokens:
                zh_vocab.word_freq[token] += 1
    
    # æ·»åŠ é«˜é¢‘è¯
    print("ðŸ”§ æ·»åŠ é«˜é¢‘è‹±æ–‡è¯...")
    en_sorted = sorted(en_vocab.word_freq.items(), key=lambda x: x[1], reverse=True)
    for word, freq in en_sorted:
        if word not in en_vocab.word2idx:
            if freq >= 2:
                if len(en_vocab) < Config.MAX_VOCAB:
                    en_vocab.add_word(word)
                else:
                    break
    
    print("ðŸ”§ æ·»åŠ é«˜é¢‘ä¸­æ–‡è¯...")
    zh_sorted = sorted(zh_vocab.word_freq.items(), key=lambda x: x[1], reverse=True)
    for word, freq in zh_sorted:
        if word not in zh_vocab.word2idx:
            if freq >= 2:
                if len(zh_vocab) < Config.MAX_VOCAB:
                    zh_vocab.add_word(word)
                else:
                    break
    
    print(f"è‹±æ–‡è¯æ±‡è¡¨: {len(en_vocab)}")
    print(f"ä¸­æ–‡è¯æ±‡è¡¨: {len(zh_vocab)}")
    
    # ä¿å­˜è¯æ±‡è¡¨
    print("ðŸ’¾ ä¿å­˜è¯æ±‡è¡¨...")
    os.makedirs(Config.VOCAB_DIR, exist_ok=True)
    en_vocab.save(f"{Config.VOCAB_DIR}/en_vocab.pkl")
    zh_vocab.save(f"{Config.VOCAB_DIR}/zh_vocab.pkl")
    
    # æµ‹è¯•
    print("\nðŸ§ª æµ‹è¯•è¯æ±‡è¡¨:")
    test_cases = [
        ("A group of men are loading cotton onto a truck", "ä¸€ç¾¤äººæŠŠæ£‰èŠ±è£…ä¸Šå¡è½¦"),
        ("A man sleeping in a green room on a couch.", "ä¸€ä¸ªäººç¡åœ¨æ²™å‘ä¸Šçš„ç»¿è‰²æˆ¿é—´"),
    ]
    
    for en, zh in test_cases:
        print(f"\nè‹±æ–‡: '{en}'")
        en_encoded = en_vocab.encode(en)
        print(f"  ç¼–ç : {en_encoded}")
        print(f"  è§£ç : '{en_vocab.decode(en_encoded)}'")
        
        print(f"ä¸­æ–‡: '{zh}'")
        zh_encoded = zh_vocab.encode(zh)
        print(f"  ç¼–ç : {zh_encoded}")
        print(f"  è§£ç : '{zh_vocab.decode(zh_encoded)}'")

if __name__ == "__main__":
    build_vocabularies()