"""æ¨ç†æ¨¡å—"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn.functional as F
from config import Config
from vocabulary import Vocabulary
from model import build_model

# å·¥å…·å‡½æ•°ï¼šç”Ÿæˆä¸‹ä¸‰è§’æ©ç ï¼ˆç”¨äºè§£ç ï¼‰
def generate_square_subsequent_mask(sz):
    """ç”Ÿæˆ [sz, sz] çš„å› æœæ©ç """
    mask = torch.triu(torch.ones(sz, sz), diagonal=1)
    return mask == 1  # True è¡¨ç¤ºè¦å±è”½çš„ä½ç½®

def load_model(model_path):
    """åŠ è½½æ¨¡å‹"""
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    
    # åŠ è½½è¯æ±‡è¡¨
    en_vocab = Vocabulary.load(f"{Config.VOCAB_DIR}/en_vocab.pkl")
    zh_vocab = Vocabulary.load(f"{Config.VOCAB_DIR}/zh_vocab.pkl")
    
    # æ„å»ºæ¨¡å‹ï¼ˆæ³¨æ„ï¼šbuild_model å†…éƒ¨å·² .to(device)ï¼‰
    device = Config.DEVICE
    model = build_model(len(en_vocab), len(zh_vocab), device)
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"è®­ç»ƒè½®æ•°: {checkpoint['epoch']}")
    print(f"éªŒè¯æŸå¤±: {checkpoint['val_loss']:.4f}")
    
    return model, en_vocab, zh_vocab, device

def translate(model, sentence, en_vocab, zh_vocab, device, temperature=0.8, max_len=50):
    """ç¿»è¯‘å•å¥ï¼ˆgreedy + temperature samplingï¼‰"""
    model.eval()
    
    # 1. ç¼–ç è¾“å…¥å¥å­ï¼ˆå‡è®¾ Vocabulary.encode è¿”å›å¸¦ <sos>/<eos> çš„ ID åˆ—è¡¨ï¼‰
    src_indices = en_vocab.encode(sentence, add_special_tokens=True)
    src = torch.tensor(src_indices).unsqueeze(0).to(device)  # [1, S]
    
    # 2. å‡†å¤‡ç›®æ ‡åºåˆ—èµ·å§‹
    sos_id = zh_vocab.word2idx[Config.SOS_TOKEN]
    eos_id = zh_vocab.word2idx[Config.EOS_TOKEN]
    pad_id = zh_vocab.word2idx[Config.PAD_TOKEN]
    
    tgt_indices = [sos_id]  # èµ·å§‹ token
    
    with torch.no_grad():
        for i in range(max_len - 1):  # é¢„ç•™ <eos>
            tgt = torch.tensor(tgt_indices).unsqueeze(0).to(device)  # [1, T]
            
            # æ„é€  masks
            src_padding_mask = (src == en_vocab.word2idx[Config.PAD_TOKEN])       # [1, S]
            tgt_padding_mask = (tgt == pad_id)                                   # [1, T]
            tgt_mask = generate_square_subsequent_mask(tgt.size(1)).to(device)   # [T, T]
            
            # å‰å‘ä¼ æ’­
            output, _ = model(
                src=src,
                tgt=tgt,
                tgt_mask=tgt_mask,
                src_padding_mask=src_padding_mask,
                tgt_padding_mask=tgt_padding_mask
            )  # output: [1, T, vocab_size]
            
            # å–æœ€åä¸€ä¸ª token çš„ logits
            next_token_logits = output[0, -1, :] / temperature
            probs = F.softmax(next_token_logits, dim=-1)
            next_token = torch.multinomial(probs, 1).item()
            
            tgt_indices.append(next_token)
            
            if next_token == eos_id:
                break
        
        # è§£ç ï¼ˆè·³è¿‡ <sos>ï¼Œé‡åˆ° <eos> åœæ­¢ï¼‰
        translation = zh_vocab.decode(tgt_indices[1:])  # decode å†…éƒ¨åº”å¤„ç† <eos>
        return translation

def main():
    """ä¸»æ¨ç†å‡½æ•°"""
    print("ğŸ”¤ ç¿»è¯‘æµ‹è¯•")
    print("=" * 60)
    
    model, en_vocab, zh_vocab, device = load_model(f"{Config.CHECKPOINT_DIR}/best_model.pth")
    
    test_sentences = [
        "A group of men are loading cotton onto a truck",
        "A man sleeping in a green room on a couch.",
        "A boy wearing headphones sits on a woman's shoulders.",
        "Two people are building a blue ice house by the lake",
        "A woman is cooking food in the kitchen",
        "A dog is running in the park",
        "A cat is sleeping on the sofa",
        "Children are playing in the playground",
        "Nice to meet you",
        "Hello world"
    ]
    
    print("\nğŸ“ ç¿»è¯‘ç»“æœ:")
    for sentence in test_sentences:
        try:
            translation = translate(model, sentence, en_vocab, zh_vocab, device, temperature=0.8)
            print(f"è‹±æ–‡: {sentence}")
            print(f"ä¸­æ–‡: {translation}")
            print("-" * 40)
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
            print("-" * 40)

if __name__ == "__main__":
    main()